---
title: Y-Squeeze 介绍
description: Y-Squeeze 框架介绍
icon: ArrowBigDown
---

## 下载安装
> 建议使用启动器方式

### 1.使用Y-Agent-launch启动器

使用Y-Agent-launch启动器，快捷方便，无需复杂配置，同时不会影响本机Python环境。

<Cards>
  <Card   title="Gitee下载链接" >
点击
  </Card>
  <Card  title="Github下载链接" >
点击
  </Card>  
</Cards>

下载完成后，解压缩，然后双击 `Y-Agent-launch.exe` 启动程序。
<Wrapper>
![](../imgs/y_agent_launch.png)
</Wrapper>


首次启动项目，会自动创建Python嵌入式虚拟环境，并自动下载依赖，请耐心等待。


> 如需更复杂设置，可以使用源码方式
###  2.从源码安装启动
从Git仓库下载
<Cards>
  <Card   title="Gitee下载链接" >
```
git clone https://gitee.com/yafo-ai/y-squeeze.git
```
  </Card>
  <Card  title="Github下载链接" >
```
git clone https://github.com/yafo-ai/y-squeeze.git
```
  </Card>  
</Cards>
创建conda环境
```
conda create --name y-squeeze python=3.11.8
```

启动conda环境
```
conda activate y-squeeze
```

安装依赖（注意命令所在目录）
```
cd y-squeeze/src
pip install -r requirements.txt
```

### 设置模型路径

<Steps>
<Step title="下载模型">
您可以从社区下载需要使用的模型源码。注意需要下载
</Step>
<Step title="放置模型">
将您需要加载的模型文件，放在 `D:/llm/` 目录下。当然可以是使用您自己的目录，建立路径中不要有中文和空格。
</Step>
<Step title="修改配置">
然后修改 `src/configs/server_config.py` 文件中的 `MODEL_DIR` 变量为您的模型路径。注意： `MODEL_DIR` 应该是模型所在的上级目录。

如果使用启动器的话，可以在设置界面的 `启动参数` 中，修改模型路径。
</Step>
</Steps>

## 功能介绍

Y-Squeeze 主要是一个研究模型内部状态的框架，这也是我们经常用来分析模型注意力分配、训练效果的工具。

> 目前支持的模型有：所有基于 Decoder-only（仅解码器）架构的、为自回归文本生成而设计的大语言模型
如：GPT 系列、LLaMA 系、Qwen 等。

### 主要功能：

#### 1. 注意力分数

分析模型内部运行时的注意力分数，是理解模型内部状态的重要步骤。

此功能可以查看模型输入输出直接，每个token的注意力在哪里，以及对其他token的注意力分数。

注意力机制研究的论文有很多，但是我们第一版的源码，借鉴了北京师范大学的代码：https://github.com/CapitalCode2020/InfiniRetri2

在这里感谢你们所作的工作，同时也希望你们在新的理论研究项目中进展顺利！

注意：正式版将修复一些已知问题，并增加一些新功能。10月发布。

#### 2. token损失分析

通常这个功能是用来分析对比模型自身输出，和我们期望输出的loss差异。

#### 3. token熵分析

通常这个功能是用来分析模型训练之后的token的熵，来判断模型能力破坏的程度。

#### 4. 内容压缩（实验性质）

同第一点，但是在我们的实验环境中，效果不如预期，所以我们准备研究其他解决方案。

#### 5. 样本生成：自动生成样本

这部分功能本身和 Y-Trainer 的功能一致，放在本项目中是为了方便训练人员，临时查看预料生成的效果。

#### 6. 特征提取与聚类筛选：

通常K-means聚类的效果不是很理想。

本功能是，对多个文本进行特征提取后，利用K-means算法进行聚类。

通常提取特征使用的模型，需要和训练的模型使用同一个，因为模型认为是不是同一类的语料，通常和我们想的不一样。

#### 7. 预训练知识欠缺分析 此功能10月正式版开放

在垂直领域，我们如何才能知道模型对哪些知识不懂，或者比较模糊？

这个功能通过算法，可以识别出模型对哪些知识点概念模糊。

简单来说就是基座模型，在预训练的时候，相关知识点的语料过少，或者没有。

如果我们能分析出模型欠缺的知识点，那么我们就可以针对性的生产语料。


#### 8. 语料质量评分 此功能10月正式版开放

你在指令微调的时候是不是遇到过，一条有问题的语料导致模型能力被破坏？指令遵循能力大幅下降或者胡言乱语？

这个功能是为了解决以上问题的。

通过识别模型的推理参数，利用算法，对SFT语料进行质量评分，快速识别出有问题的语料。

评分都是基于要微调的模型来计算的。

有的时候，我们人类认为没有问题的语料，对于模型是有问题的。所以这个功能是很有帮助的。

同时由于可以对语料进行评分，我们可以对语料排序，由易到难的训练模型。

